{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "\n",
    "datadir = '/Users/dragonjohn/Documents/DevEnv/Python/MLCR2malwareDetect/dataset/'\n",
    "train_CSV_file = 'train.csv'\n",
    "output_train_csv_file = 'train_data.csv'\n",
    "output_test_csv_file = 'test_data.csv'\n",
    "\n",
    "info_feature_selected = [1, 4, 7, 8, 9, 11, 12, 14, 18, 23, 26, 29, 30, 32, 33, 34]\n",
    "\n",
    "if len(sys.argv)>=2:\n",
    "    datadir = sys.argv[1]\n",
    "else:\n",
    "    print \"no dataset directory provided\"\n",
    "    exit(1)\n",
    "\n",
    "def select_info_feature():\n",
    "    selected_label = []\n",
    "    with open('info_label.txt', 'rb') as info_label_file:\n",
    "        labels = info_label_file.readlines()\n",
    "        for idx, row in enumerate(labels):\n",
    "            if idx in info_feature_selected:\n",
    "                selected_label.append(row.rstrip())\n",
    "    return selected_label\n",
    "\n",
    "def get_info_train_dataset(selected_features):\n",
    "    train_x = []\n",
    "    title_row = ['label']+ selected_features\n",
    "    train_x.append(title_row)\n",
    "    with open(datadir + train_CSV_file, 'rb') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter = ',', quotechar='\"')\n",
    "        for row in spamreader:\n",
    "            data_row = []\n",
    "            data_row.append(row[1])\n",
    "            with open(datadir + 'train/' + row[0] + '/info') as info_file:\n",
    "                data = json.load(info_file)\n",
    "                for key, value in data.items():\n",
    "                    if key in selected_features:\n",
    "                        data_row.append(value)\n",
    "            train_x.append(data_row)\n",
    "    return train_x\n",
    "\n",
    "def get_info_test_dataset(selected_features):\n",
    "    test_x = []\n",
    "    for filefolder in os.listdir(datadir + 'test/'):\n",
    "        if filefolder.startswith('.'):\n",
    "            continue\n",
    "        data_row = []\n",
    "        data_row.append(filefolder)\n",
    "        with open(datadir + 'test/' + filefolder +'/info') as info_file:\n",
    "            data = json.load(info_file)\n",
    "            for key, value in data.items():\n",
    "                if key in selected_features:\n",
    "                    data_row.append(value)\n",
    "        test_x.append(data_row)\n",
    "    return test_x\n",
    "\n",
    "def get_info_test_new_dataset(selected_features):\n",
    "    test_x = []\n",
    "    for filefolder in os.listdir(datadir + 'test-new/'):\n",
    "        if filefolder.startswith('.'):\n",
    "            continue\n",
    "        data_row = []\n",
    "        data_row.append(filefolder)\n",
    "        with open(datadir + 'test-new/' + filefolder +'/info') as info_file:\n",
    "            data = json.load(info_file)\n",
    "            for key, value in data.items():\n",
    "                if key in selected_features:\n",
    "                    data_row.append(value)\n",
    "        test_x.append(data_row)\n",
    "    return test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dragonjohn/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "f1 = pandas.read_csv('dataset/train_info.csv', comment=\"#\", header=None, engine='c', dtype={0: 'object'})\n",
    "#f1.columns\n",
    "#f1.columns = [\"label\"]+f1.columns.tolist()\n",
    "md5 = f1.ix[1:,:0]\n",
    "md5\n",
    "\n",
    "#column_attr = f1.ix[0:0,:]\n",
    "#column_attr[0][0]\n",
    "column_attr = f1.ix[0:0,:]\n",
    "if 'md5' == column_attr[0][0]:\n",
    "    print \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1 = f1.ix[1:,0:]\n",
    "#f1\n",
    "label = f1.ix[0:,1:1]\n",
    "#label\n",
    "import numpy as np\n",
    "data = f1.ix[0:,2:]\n",
    "da = np.array(data,dtype=\"float32\")\n",
    "#da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "def parsefile(filepath):\n",
    "    f = pandas.read_csv(filepath, comment=\"#\", header=None, engine='c', dtype={0: 'object'})\n",
    "\n",
    "    md5 = None\n",
    "    label = None\n",
    "    data = None\n",
    "\n",
    "    drop_cols = [54,66,68,69,72,74,81,83,85,87,89,90,95,98,106,109,111,116,117,121,135,\n",
    "                 137,140,142,147,149,160,163,165,166,168,171,172,175,176,180,181,185,187,\n",
    "                 194,202,203,205,209,193,101,119,206,110,199,46,108,64,120,19,63]\n",
    "    \n",
    "    column_attr = f.ix[0:0,:]\n",
    "    if 'md5' == column_attr[0][0]: #train dataset with title and label\n",
    "        f = f.ix[1:,0:] #remove first row\n",
    "        la = f.ix[0:,1:1]\n",
    "        label = np.array(la,dtype=\"int\")\n",
    "        da = f.ix[0:,2:].replace(np.nan,0, regex=True)\n",
    "    else:\n",
    "        da = f.ix[0:,1:].replace(np.nan,0, regex=True)\n",
    "    md5 = f.ix[0:,:0]\n",
    "    #drop \n",
    "    da.drop(da.columns[drop_cols],axis=1,inplace=True)\n",
    "    data = np.array(da)\n",
    "    return data, label, md5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dragonjohn/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2825: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,755,756,757,758,759,760,771,772,773,774,775,776,787,788,789,790,791,792,803,804,805,806,807,808,819,820,821,822,823,824,835,836,837,838,839,840,851,852,853,854,855,856,867,868,869,870,871,872,883,884,885,886,887,888,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ..., \n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD TRAIN DATA\n",
    "data, label, md5 = parsefile('dataset/train_info+import+asm+rom_select.csv')\n",
    "#LOAD TEST DATA\n",
    "tdata, tlable, tmd5 = parsefile('dataset/test_info+import+asm.csv')\n",
    "\n",
    "# data : ndarray\n",
    "# label : Dataframe\n",
    "##import numpy as np\n",
    "##np.asarray(label.as_matrix().transpose().tolist()[0])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1397712580', '7.999983194', '4096', ..., '0', '0', '0'],\n",
       "       ['584634781', '7.692392195', '4096', ..., '0', '3298', '0'],\n",
       "       ['1339084793', '6.61794597', '16384', ..., '0', '263291', '0'],\n",
       "       ..., \n",
       "       [1439716561, 4096.0, 0, ..., 0, 79229, 0],\n",
       "       [1437064938, 7.987133351000001, 4096, ..., 0, 245131, 0],\n",
       "       [1330111183, 6.249088989, 4096, ..., 0, 13016, 0]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "#X = data\n",
    "#y = label\n",
    "X, y = make_blobs(n_samples=10, n_features=2, random_state=42,\n",
    "                  cluster_std=5.0)\n",
    "X_train, y_train = X[:600], y[:600]\n",
    "X_valid, y_valid = X[600:800], y[600:800]\n",
    "X_train_valid, y_train_valid = X[:800], y[:800]\n",
    "X_test, y_test = X[800:], y[800:]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = make_blobs(n_samples=10000, n_features=10, centers=100,\n",
    "    random_state=0)\n",
    "                        \n",
    "#clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "#    min_samples_split=1, random_state=0)\n",
    "#scores = cross_val_score(clf, X, y)\n",
    "#scores.mean()                             \n",
    "\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=1, random_state=0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "scores.mean() > 0.999\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.46907649,   4.25070317,  -8.63694437, ...,  -0.48172814,\n",
       "         -6.44996141,  -2.65984972],\n",
       "       [  6.48856404,   9.37957037,  10.32791736, ...,   3.37542134,\n",
       "          7.41273719,  -9.72284371],\n",
       "       [  8.37392753, -10.14342267,  -3.52753613, ...,  -7.31536045,\n",
       "         -2.33070872,   6.44087163],\n",
       "       ..., \n",
       "       [  7.86551596,   6.19525794,   4.773955  , ...,   4.93452091,\n",
       "         -4.52137856,   6.28178851],\n",
       "       [-10.41156442,   1.40054826,  -1.97349572, ...,  -3.18210433,\n",
       "          7.59487579,   4.62753678],\n",
       "       [  7.40908901,  -7.3908382 ,  10.78350645, ...,  -3.26219501,\n",
       "          5.73727272,  -4.97354916]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85, 64, 93, ..., 98, 80, 91])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = data\n",
    "y = label.transpose()[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1397712580', '7.999983194', '4096', ..., '0', '0', '0'],\n",
       "       ['584634781', '7.692392195', '4096', ..., '0', '3298', '0'],\n",
       "       ['1339084793', '6.61794597', '16384', ..., '0', '263291', '0'],\n",
       "       ..., \n",
       "       [1439716561, 4096.0, 0, ..., 0, 79229, 0],\n",
       "       [1437064938, 7.987133351000001, 4096, ..., 0, 245131, 0],\n",
       "       [1330111183, 6.249088989, 4096, ..., 0, 13016, 0]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 969)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97158003670758786"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=250, max_depth=None, \n",
    "    criterion='entropy',\n",
    "    min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Feature ranking:\n",
      "1. feature 943 (0.026503)\n",
      "2. feature 945 (0.020969)\n",
      "3. feature 966 (0.013190)\n",
      "4. feature 400 (0.008730)\n",
      "5. feature 288 (0.007884)\n",
      "6. feature 256 (0.007567)\n",
      "7. feature 336 (0.007403)\n",
      "8. feature 359 (0.006352)\n",
      "9. feature 622 (0.005554)\n",
      "10. feature 329 (0.005462)\n",
      "11. feature 482 (0.005425)\n",
      "12. feature 485 (0.004937)\n",
      "13. feature 244 (0.004682)\n",
      "14. feature 653 (0.004425)\n",
      "15. feature 221 (0.004326)\n",
      "16. feature 7 (0.004318)\n",
      "17. feature 654 (0.004256)\n",
      "18. feature 0 (0.004042)\n",
      "19. feature 594 (0.003962)\n",
      "20. feature 602 (0.003666)\n",
      "21. feature 467 (0.003413)\n",
      "22. feature 230 (0.003384)\n",
      "23. feature 432 (0.003333)\n",
      "24. feature 609 (0.003317)\n",
      "25. feature 1 (0.003281)\n",
      "26. feature 314 (0.003029)\n",
      "27. feature 8 (0.003026)\n",
      "28. feature 665 (0.003016)\n",
      "29. feature 281 (0.002928)\n",
      "30. feature 259 (0.002890)\n",
      "31. feature 376 (0.002739)\n",
      "32. feature 268 (0.002709)\n",
      "33. feature 632 (0.002664)\n",
      "34. feature 6 (0.002609)\n",
      "35. feature 566 (0.002595)\n",
      "36. feature 247 (0.002555)\n",
      "37. feature 681 (0.002540)\n",
      "38. feature 15 (0.002491)\n",
      "39. feature 421 (0.002486)\n",
      "40. feature 16 (0.002481)\n",
      "41. feature 251 (0.002456)\n",
      "42. feature 593 (0.002446)\n",
      "43. feature 551 (0.002326)\n",
      "44. feature 883 (0.002318)\n",
      "45. feature 207 (0.002289)\n",
      "46. feature 394 (0.002249)\n",
      "47. feature 297 (0.002215)\n",
      "48. feature 351 (0.002181)\n",
      "49. feature 328 (0.002179)\n",
      "50. feature 612 (0.002149)\n",
      "51. feature 953 (0.002137)\n",
      "52. feature 293 (0.002132)\n",
      "53. feature 866 (0.002127)\n",
      "54. feature 662 (0.002111)\n",
      "55. feature 640 (0.002106)\n",
      "56. feature 271 (0.002097)\n",
      "57. feature 218 (0.002051)\n",
      "58. feature 820 (0.002017)\n",
      "59. feature 655 (0.002011)\n",
      "60. feature 286 (0.001987)\n",
      "61. feature 555 (0.001958)\n",
      "62. feature 379 (0.001951)\n",
      "63. feature 411 (0.001908)\n",
      "64. feature 381 (0.001903)\n",
      "65. feature 303 (0.001876)\n",
      "66. feature 604 (0.001875)\n",
      "67. feature 873 (0.001873)\n",
      "68. feature 611 (0.001866)\n",
      "69. feature 380 (0.001823)\n",
      "70. feature 646 (0.001818)\n",
      "71. feature 811 (0.001802)\n",
      "72. feature 837 (0.001801)\n",
      "73. feature 320 (0.001800)\n",
      "74. feature 436 (0.001797)\n",
      "75. feature 438 (0.001797)\n",
      "76. feature 928 (0.001781)\n",
      "77. feature 858 (0.001777)\n",
      "78. feature 387 (0.001753)\n",
      "79. feature 882 (0.001741)\n",
      "80. feature 524 (0.001729)\n",
      "81. feature 698 (0.001726)\n",
      "82. feature 366 (0.001714)\n",
      "83. feature 930 (0.001697)\n",
      "84. feature 280 (0.001694)\n",
      "85. feature 852 (0.001687)\n",
      "86. feature 881 (0.001682)\n",
      "87. feature 397 (0.001678)\n",
      "88. feature 613 (0.001678)\n",
      "89. feature 565 (0.001677)\n",
      "90. feature 926 (0.001677)\n",
      "91. feature 417 (0.001676)\n",
      "92. feature 660 (0.001673)\n",
      "93. feature 747 (0.001672)\n",
      "94. feature 847 (0.001658)\n",
      "95. feature 893 (0.001643)\n",
      "96. feature 894 (0.001642)\n",
      "97. feature 891 (0.001641)\n",
      "98. feature 615 (0.001640)\n",
      "99. feature 860 (0.001637)\n",
      "100. feature 770 (0.001637)\n",
      "101. feature 704 (0.001596)\n",
      "102. feature 905 (0.001579)\n",
      "103. feature 927 (0.001579)\n",
      "104. feature 826 (0.001576)\n",
      "105. feature 603 (0.001575)\n",
      "106. feature 630 (0.001571)\n",
      "107. feature 383 (0.001569)\n",
      "108. feature 764 (0.001567)\n",
      "109. feature 717 (0.001563)\n",
      "110. feature 775 (0.001556)\n",
      "111. feature 552 (0.001552)\n",
      "112. feature 215 (0.001545)\n",
      "113. feature 851 (0.001540)\n",
      "114. feature 687 (0.001535)\n",
      "115. feature 700 (0.001535)\n",
      "116. feature 523 (0.001530)\n",
      "117. feature 906 (0.001523)\n",
      "118. feature 322 (0.001519)\n",
      "119. feature 929 (0.001516)\n",
      "120. feature 688 (0.001510)\n",
      "121. feature 872 (0.001510)\n",
      "122. feature 886 (0.001504)\n",
      "123. feature 440 (0.001502)\n",
      "124. feature 480 (0.001501)\n",
      "125. feature 788 (0.001495)\n",
      "126. feature 249 (0.001493)\n",
      "127. feature 11 (0.001491)\n",
      "128. feature 843 (0.001486)\n",
      "129. feature 918 (0.001484)\n",
      "130. feature 393 (0.001482)\n",
      "131. feature 679 (0.001482)\n",
      "132. feature 715 (0.001481)\n",
      "133. feature 762 (0.001474)\n",
      "134. feature 525 (0.001473)\n",
      "135. feature 849 (0.001472)\n",
      "136. feature 813 (0.001468)\n",
      "137. feature 270 (0.001459)\n",
      "138. feature 861 (0.001458)\n",
      "139. feature 13 (0.001449)\n",
      "140. feature 897 (0.001448)\n",
      "141. feature 711 (0.001447)\n",
      "142. feature 743 (0.001446)\n",
      "143. feature 880 (0.001445)\n",
      "144. feature 773 (0.001440)\n",
      "145. feature 931 (0.001437)\n",
      "146. feature 914 (0.001435)\n",
      "147. feature 913 (0.001431)\n",
      "148. feature 148 (0.001431)\n",
      "149. feature 902 (0.001431)\n",
      "150. feature 949 (0.001429)\n",
      "151. feature 892 (0.001426)\n",
      "152. feature 821 (0.001415)\n",
      "153. feature 779 (0.001411)\n",
      "154. feature 458 (0.001408)\n",
      "155. feature 935 (0.001406)\n",
      "156. feature 889 (0.001402)\n",
      "157. feature 947 (0.001401)\n",
      "158. feature 815 (0.001401)\n",
      "159. feature 923 (0.001401)\n",
      "160. feature 850 (0.001394)\n",
      "161. feature 689 (0.001387)\n",
      "162. feature 500 (0.001386)\n",
      "163. feature 944 (0.001386)\n",
      "164. feature 691 (0.001386)\n",
      "165. feature 756 (0.001379)\n",
      "166. feature 791 (0.001378)\n",
      "167. feature 157 (0.001377)\n",
      "168. feature 793 (0.001376)\n",
      "169. feature 461 (0.001370)\n",
      "170. feature 836 (0.001368)\n",
      "171. feature 239 (0.001368)\n",
      "172. feature 856 (0.001362)\n",
      "173. feature 794 (0.001362)\n",
      "174. feature 799 (0.001358)\n",
      "175. feature 17 (0.001353)\n",
      "176. feature 870 (0.001352)\n",
      "177. feature 511 (0.001351)\n",
      "178. feature 165 (0.001345)\n",
      "179. feature 848 (0.001345)\n",
      "180. feature 796 (0.001344)\n",
      "181. feature 733 (0.001344)\n",
      "182. feature 765 (0.001341)\n",
      "183. feature 809 (0.001338)\n",
      "184. feature 701 (0.001337)\n",
      "185. feature 355 (0.001336)\n",
      "186. feature 907 (0.001335)\n",
      "187. feature 706 (0.001335)\n",
      "188. feature 741 (0.001334)\n",
      "189. feature 940 (0.001333)\n",
      "190. feature 709 (0.001333)\n",
      "191. feature 828 (0.001332)\n",
      "192. feature 608 (0.001332)\n",
      "193. feature 816 (0.001327)\n",
      "194. feature 890 (0.001325)\n",
      "195. feature 514 (0.001323)\n",
      "196. feature 703 (0.001322)\n",
      "197. feature 690 (0.001321)\n",
      "198. feature 888 (0.001319)\n",
      "199. feature 69 (0.001319)\n",
      "200. feature 855 (0.001319)\n",
      "201. feature 452 (0.001319)\n",
      "202. feature 798 (0.001311)\n",
      "203. feature 801 (0.001310)\n",
      "204. feature 884 (0.001309)\n",
      "205. feature 638 (0.001308)\n",
      "206. feature 18 (0.001307)\n",
      "207. feature 760 (0.001307)\n",
      "208. feature 739 (0.001307)\n",
      "209. feature 576 (0.001298)\n",
      "210. feature 571 (0.001295)\n",
      "211. feature 805 (0.001295)\n",
      "212. feature 732 (0.001288)\n",
      "213. feature 162 (0.001288)\n",
      "214. feature 862 (0.001287)\n",
      "215. feature 790 (0.001286)\n",
      "216. feature 903 (0.001285)\n",
      "217. feature 695 (0.001284)\n",
      "218. feature 437 (0.001284)\n",
      "219. feature 441 (0.001278)\n",
      "220. feature 347 (0.001277)\n",
      "221. feature 755 (0.001277)\n",
      "222. feature 766 (0.001276)\n",
      "223. feature 878 (0.001274)\n",
      "224. feature 864 (0.001273)\n",
      "225. feature 154 (0.001273)\n",
      "226. feature 840 (0.001273)\n",
      "227. feature 75 (0.001272)\n",
      "228. feature 822 (0.001270)\n",
      "229. feature 713 (0.001267)\n",
      "230. feature 160 (0.001264)\n",
      "231. feature 795 (0.001263)\n",
      "232. feature 568 (0.001263)\n",
      "233. feature 115 (0.001262)\n",
      "234. feature 792 (0.001259)\n",
      "235. feature 583 (0.001259)\n",
      "236. feature 853 (0.001259)\n",
      "237. feature 932 (0.001259)\n",
      "238. feature 553 (0.001259)\n",
      "239. feature 196 (0.001258)\n",
      "240. feature 641 (0.001258)\n",
      "241. feature 402 (0.001257)\n",
      "242. feature 241 (0.001253)\n",
      "243. feature 887 (0.001247)\n",
      "244. feature 806 (0.001246)\n",
      "245. feature 835 (0.001243)\n",
      "246. feature 817 (0.001242)\n",
      "247. feature 290 (0.001233)\n",
      "248. feature 832 (0.001232)\n",
      "249. feature 731 (0.001229)\n",
      "250. feature 758 (0.001227)\n",
      "251. feature 584 (0.001226)\n",
      "252. feature 754 (0.001224)\n",
      "253. feature 941 (0.001223)\n",
      "254. feature 104 (0.001221)\n",
      "255. feature 934 (0.001216)\n",
      "256. feature 172 (0.001215)\n",
      "257. feature 879 (0.001215)\n",
      "258. feature 10 (0.001213)\n",
      "259. feature 456 (0.001212)\n",
      "260. feature 830 (0.001211)\n",
      "261. feature 719 (0.001210)\n",
      "262. feature 727 (0.001208)\n",
      "263. feature 807 (0.001207)\n",
      "264. feature 413 (0.001204)\n",
      "265. feature 917 (0.001202)\n",
      "266. feature 895 (0.001201)\n",
      "267. feature 909 (0.001195)\n",
      "268. feature 771 (0.001195)\n",
      "269. feature 885 (0.001195)\n",
      "270. feature 857 (0.001195)\n",
      "271. feature 168 (0.001193)\n",
      "272. feature 501 (0.001193)\n",
      "273. feature 785 (0.001192)\n",
      "274. feature 386 (0.001191)\n",
      "275. feature 824 (0.001191)\n",
      "276. feature 752 (0.001189)\n",
      "277. feature 780 (0.001189)\n",
      "278. feature 696 (0.001187)\n",
      "279. feature 699 (0.001185)\n",
      "280. feature 729 (0.001183)\n",
      "281. feature 542 (0.001183)\n",
      "282. feature 495 (0.001183)\n",
      "283. feature 316 (0.001181)\n",
      "284. feature 43 (0.001175)\n",
      "285. feature 761 (0.001173)\n",
      "286. feature 678 (0.001171)\n",
      "287. feature 804 (0.001169)\n",
      "288. feature 936 (0.001163)\n",
      "289. feature 915 (0.001163)\n",
      "290. feature 493 (0.001161)\n",
      "291. feature 710 (0.001159)\n",
      "292. feature 712 (0.001157)\n",
      "293. feature 865 (0.001157)\n",
      "294. feature 586 (0.001151)\n",
      "295. feature 782 (0.001150)\n",
      "296. feature 854 (0.001149)\n",
      "297. feature 818 (0.001148)\n",
      "298. feature 875 (0.001144)\n",
      "299. feature 64 (0.001143)\n",
      "300. feature 802 (0.001141)\n",
      "301. feature 559 (0.001139)\n",
      "302. feature 234 (0.001135)\n",
      "303. feature 783 (0.001134)\n",
      "304. feature 772 (0.001132)\n",
      "305. feature 708 (0.001131)\n",
      "306. feature 956 (0.001130)\n",
      "307. feature 101 (0.001129)\n",
      "308. feature 302 (0.001127)\n",
      "309. feature 842 (0.001127)\n",
      "310. feature 35 (0.001126)\n",
      "311. feature 800 (0.001125)\n",
      "312. feature 896 (0.001125)\n",
      "313. feature 942 (0.001124)\n",
      "314. feature 372 (0.001124)\n",
      "315. feature 845 (0.001123)\n",
      "316. feature 838 (0.001122)\n",
      "317. feature 466 (0.001118)\n",
      "318. feature 90 (0.001116)\n",
      "319. feature 629 (0.001112)\n",
      "320. feature 214 (0.001111)\n",
      "321. feature 939 (0.001109)\n",
      "322. feature 938 (0.001108)\n",
      "323. feature 912 (0.001105)\n",
      "324. feature 745 (0.001105)\n",
      "325. feature 161 (0.001105)\n",
      "326. feature 24 (0.001104)\n",
      "327. feature 63 (0.001104)\n",
      "328. feature 702 (0.001102)\n",
      "329. feature 74 (0.001099)\n",
      "330. feature 468 (0.001098)\n",
      "331. feature 808 (0.001096)\n",
      "332. feature 749 (0.001095)\n",
      "333. feature 919 (0.001094)\n",
      "334. feature 812 (0.001091)\n",
      "335. feature 751 (0.001091)\n",
      "336. feature 738 (0.001090)\n",
      "337. feature 871 (0.001084)\n",
      "338. feature 921 (0.001084)\n",
      "339. feature 412 (0.001080)\n",
      "340. feature 901 (0.001079)\n",
      "341. feature 868 (0.001077)\n",
      "342. feature 833 (0.001077)\n",
      "343. feature 107 (0.001075)\n",
      "344. feature 786 (0.001075)\n",
      "345. feature 869 (0.001074)\n",
      "346. feature 661 (0.001074)\n",
      "347. feature 736 (0.001072)\n",
      "348. feature 673 (0.001070)\n",
      "349. feature 922 (0.001068)\n",
      "350. feature 276 (0.001067)\n",
      "351. feature 539 (0.001067)\n",
      "352. feature 693 (0.001066)\n",
      "353. feature 797 (0.001065)\n",
      "354. feature 784 (0.001065)\n",
      "355. feature 908 (0.001064)\n",
      "356. feature 718 (0.001060)\n",
      "357. feature 819 (0.001059)\n",
      "358. feature 920 (0.001057)\n",
      "359. feature 774 (0.001054)\n",
      "360. feature 750 (0.001053)\n",
      "361. feature 748 (0.001053)\n",
      "362. feature 150 (0.001052)\n",
      "363. feature 925 (0.001051)\n",
      "364. feature 789 (0.001051)\n",
      "365. feature 742 (0.001050)\n",
      "366. feature 72 (0.001047)\n",
      "367. feature 910 (0.001046)\n",
      "368. feature 946 (0.001044)\n",
      "369. feature 831 (0.001044)\n",
      "370. feature 814 (0.001041)\n",
      "371. feature 39 (0.001039)\n",
      "372. feature 512 (0.001038)\n",
      "373. feature 254 (0.001037)\n",
      "374. feature 967 (0.001037)\n",
      "375. feature 787 (0.001036)\n",
      "376. feature 720 (0.001033)\n",
      "377. feature 159 (0.001033)\n",
      "378. feature 558 (0.001032)\n",
      "379. feature 451 (0.001031)\n",
      "380. feature 763 (0.001030)\n",
      "381. feature 716 (0.001029)\n",
      "382. feature 839 (0.001029)\n",
      "383. feature 767 (0.001029)\n",
      "384. feature 61 (0.001029)\n",
      "385. feature 388 (0.001026)\n",
      "386. feature 705 (0.001026)\n",
      "387. feature 274 (0.001024)\n",
      "388. feature 916 (0.001021)\n",
      "389. feature 728 (0.001018)\n",
      "390. feature 269 (0.001018)\n",
      "391. feature 734 (0.001018)\n",
      "392. feature 707 (0.001017)\n",
      "393. feature 55 (0.001017)\n",
      "394. feature 96 (0.001015)\n",
      "395. feature 937 (0.001014)\n",
      "396. feature 197 (0.001014)\n",
      "397. feature 768 (0.001012)\n",
      "398. feature 697 (0.001006)\n",
      "399. feature 721 (0.001006)\n",
      "400. feature 642 (0.001005)\n",
      "401. feature 428 (0.001004)\n",
      "402. feature 735 (0.001003)\n",
      "403. feature 899 (0.001003)\n",
      "404. feature 518 (0.001002)\n",
      "405. feature 483 (0.001001)\n",
      "406. feature 740 (0.001001)\n",
      "407. feature 385 (0.000999)\n",
      "408. feature 898 (0.000995)\n",
      "409. feature 757 (0.000994)\n",
      "410. feature 470 (0.000983)\n",
      "411. feature 759 (0.000983)\n",
      "412. feature 146 (0.000977)\n",
      "413. feature 877 (0.000976)\n",
      "414. feature 540 (0.000971)\n",
      "415. feature 291 (0.000971)\n",
      "416. feature 620 (0.000971)\n",
      "417. feature 419 (0.000969)\n",
      "418. feature 155 (0.000965)\n",
      "419. feature 93 (0.000965)\n",
      "420. feature 823 (0.000964)\n",
      "421. feature 803 (0.000963)\n",
      "422. feature 637 (0.000962)\n",
      "423. feature 867 (0.000961)\n",
      "424. feature 769 (0.000961)\n",
      "425. feature 84 (0.000961)\n",
      "426. feature 95 (0.000958)\n",
      "427. feature 844 (0.000957)\n",
      "428. feature 561 (0.000956)\n",
      "429. feature 810 (0.000954)\n",
      "430. feature 933 (0.000953)\n",
      "431. feature 265 (0.000953)\n",
      "432. feature 674 (0.000949)\n",
      "433. feature 164 (0.000946)\n",
      "434. feature 876 (0.000946)\n",
      "435. feature 730 (0.000944)\n",
      "436. feature 777 (0.000943)\n",
      "437. feature 401 (0.000941)\n",
      "438. feature 284 (0.000940)\n",
      "439. feature 600 (0.000940)\n",
      "440. feature 778 (0.000940)\n",
      "441. feature 25 (0.000934)\n",
      "442. feature 237 (0.000934)\n",
      "443. feature 859 (0.000934)\n",
      "444. feature 825 (0.000933)\n",
      "445. feature 874 (0.000930)\n",
      "446. feature 781 (0.000930)\n",
      "447. feature 112 (0.000929)\n",
      "448. feature 422 (0.000929)\n",
      "449. feature 487 (0.000927)\n",
      "450. feature 195 (0.000926)\n",
      "451. feature 724 (0.000926)\n",
      "452. feature 300 (0.000924)\n",
      "453. feature 549 (0.000920)\n",
      "454. feature 77 (0.000918)\n",
      "455. feature 722 (0.000917)\n",
      "456. feature 50 (0.000914)\n",
      "457. feature 725 (0.000914)\n",
      "458. feature 694 (0.000913)\n",
      "459. feature 149 (0.000913)\n",
      "460. feature 85 (0.000910)\n",
      "461. feature 723 (0.000907)\n",
      "462. feature 827 (0.000906)\n",
      "463. feature 846 (0.000903)\n",
      "464. feature 834 (0.000902)\n",
      "465. feature 231 (0.000901)\n",
      "466. feature 121 (0.000900)\n",
      "467. feature 110 (0.000898)\n",
      "468. feature 3 (0.000898)\n",
      "469. feature 829 (0.000894)\n",
      "470. feature 174 (0.000892)\n",
      "471. feature 296 (0.000891)\n",
      "472. feature 267 (0.000889)\n",
      "473. feature 753 (0.000889)\n",
      "474. feature 309 (0.000888)\n",
      "475. feature 904 (0.000888)\n",
      "476. feature 737 (0.000887)\n",
      "477. feature 128 (0.000881)\n",
      "478. feature 776 (0.000880)\n",
      "479. feature 626 (0.000872)\n",
      "480. feature 618 (0.000869)\n",
      "481. feature 744 (0.000867)\n",
      "482. feature 666 (0.000866)\n",
      "483. feature 863 (0.000862)\n",
      "484. feature 911 (0.000860)\n",
      "485. feature 123 (0.000859)\n",
      "486. feature 264 (0.000858)\n",
      "487. feature 841 (0.000853)\n",
      "488. feature 56 (0.000852)\n",
      "489. feature 273 (0.000851)\n",
      "490. feature 714 (0.000850)\n",
      "491. feature 62 (0.000849)\n",
      "492. feature 4 (0.000849)\n",
      "493. feature 617 (0.000847)\n",
      "494. feature 389 (0.000847)\n",
      "495. feature 357 (0.000846)\n",
      "496. feature 73 (0.000846)\n",
      "497. feature 5 (0.000843)\n",
      "498. feature 317 (0.000841)\n",
      "499. feature 685 (0.000839)\n",
      "500. feature 692 (0.000837)\n",
      "501. feature 49 (0.000834)\n",
      "502. feature 327 (0.000832)\n",
      "503. feature 958 (0.000829)\n",
      "504. feature 319 (0.000825)\n",
      "505. feature 591 (0.000824)\n",
      "506. feature 435 (0.000820)\n",
      "507. feature 420 (0.000819)\n",
      "508. feature 248 (0.000819)\n",
      "509. feature 370 (0.000818)\n",
      "510. feature 216 (0.000815)\n",
      "511. feature 108 (0.000815)\n",
      "512. feature 142 (0.000815)\n",
      "513. feature 211 (0.000813)\n",
      "514. feature 354 (0.000811)\n",
      "515. feature 306 (0.000808)\n",
      "516. feature 924 (0.000806)\n",
      "517. feature 105 (0.000804)\n",
      "518. feature 900 (0.000801)\n",
      "519. feature 348 (0.000800)\n",
      "520. feature 311 (0.000799)\n",
      "521. feature 532 (0.000796)\n",
      "522. feature 746 (0.000795)\n",
      "523. feature 70 (0.000788)\n",
      "524. feature 257 (0.000787)\n",
      "525. feature 726 (0.000787)\n",
      "526. feature 209 (0.000785)\n",
      "527. feature 299 (0.000776)\n",
      "528. feature 648 (0.000775)\n",
      "529. feature 427 (0.000768)\n",
      "530. feature 238 (0.000766)\n",
      "531. feature 203 (0.000766)\n",
      "532. feature 308 (0.000761)\n",
      "533. feature 628 (0.000761)\n",
      "534. feature 94 (0.000760)\n",
      "535. feature 307 (0.000754)\n",
      "536. feature 410 (0.000751)\n",
      "537. feature 577 (0.000751)\n",
      "538. feature 53 (0.000750)\n",
      "539. feature 445 (0.000745)\n",
      "540. feature 114 (0.000745)\n",
      "541. feature 520 (0.000744)\n",
      "542. feature 342 (0.000744)\n",
      "543. feature 129 (0.000741)\n",
      "544. feature 567 (0.000736)\n",
      "545. feature 408 (0.000736)\n",
      "546. feature 596 (0.000736)\n",
      "547. feature 323 (0.000735)\n",
      "548. feature 156 (0.000729)\n",
      "549. feature 601 (0.000727)\n",
      "550. feature 587 (0.000727)\n",
      "551. feature 581 (0.000725)\n",
      "552. feature 669 (0.000724)\n",
      "553. feature 633 (0.000724)\n",
      "554. feature 305 (0.000721)\n",
      "555. feature 71 (0.000715)\n",
      "556. feature 184 (0.000714)\n",
      "557. feature 409 (0.000712)\n",
      "558. feature 517 (0.000705)\n",
      "559. feature 2 (0.000705)\n",
      "560. feature 98 (0.000703)\n",
      "561. feature 285 (0.000702)\n",
      "562. feature 37 (0.000701)\n",
      "563. feature 330 (0.000701)\n",
      "564. feature 535 (0.000691)\n",
      "565. feature 643 (0.000684)\n",
      "566. feature 529 (0.000683)\n",
      "567. feature 550 (0.000681)\n",
      "568. feature 554 (0.000679)\n",
      "569. feature 122 (0.000678)\n",
      "570. feature 131 (0.000678)\n",
      "571. feature 964 (0.000677)\n",
      "572. feature 226 (0.000676)\n",
      "573. feature 433 (0.000675)\n",
      "574. feature 167 (0.000673)\n",
      "575. feature 192 (0.000670)\n",
      "576. feature 657 (0.000669)\n",
      "577. feature 651 (0.000669)\n",
      "578. feature 81 (0.000668)\n",
      "579. feature 275 (0.000668)\n",
      "580. feature 599 (0.000666)\n",
      "581. feature 200 (0.000666)\n",
      "582. feature 360 (0.000665)\n",
      "583. feature 223 (0.000663)\n",
      "584. feature 658 (0.000660)\n",
      "585. feature 488 (0.000659)\n",
      "586. feature 246 (0.000657)\n",
      "587. feature 220 (0.000655)\n",
      "588. feature 570 (0.000653)\n",
      "589. feature 242 (0.000653)\n",
      "590. feature 484 (0.000648)\n",
      "591. feature 557 (0.000647)\n",
      "592. feature 213 (0.000642)\n",
      "593. feature 526 (0.000641)\n",
      "594. feature 313 (0.000641)\n",
      "595. feature 375 (0.000638)\n",
      "596. feature 684 (0.000638)\n",
      "597. feature 219 (0.000635)\n",
      "598. feature 321 (0.000633)\n",
      "599. feature 606 (0.000632)\n",
      "600. feature 623 (0.000631)\n",
      "601. feature 395 (0.000631)\n",
      "602. feature 331 (0.000630)\n",
      "603. feature 152 (0.000628)\n",
      "604. feature 680 (0.000627)\n",
      "605. feature 324 (0.000627)\n",
      "606. feature 126 (0.000626)\n",
      "607. feature 624 (0.000620)\n",
      "608. feature 283 (0.000620)\n",
      "609. feature 117 (0.000619)\n",
      "610. feature 289 (0.000619)\n",
      "611. feature 647 (0.000617)\n",
      "612. feature 99 (0.000615)\n",
      "613. feature 481 (0.000613)\n",
      "614. feature 454 (0.000611)\n",
      "615. feature 631 (0.000607)\n",
      "616. feature 340 (0.000604)\n",
      "617. feature 538 (0.000602)\n",
      "618. feature 639 (0.000602)\n",
      "619. feature 431 (0.000601)\n",
      "620. feature 490 (0.000597)\n",
      "621. feature 434 (0.000597)\n",
      "622. feature 527 (0.000597)\n",
      "623. feature 407 (0.000595)\n",
      "624. feature 560 (0.000593)\n",
      "625. feature 185 (0.000592)\n",
      "626. feature 224 (0.000589)\n",
      "627. feature 462 (0.000588)\n",
      "628. feature 163 (0.000586)\n",
      "629. feature 166 (0.000586)\n",
      "630. feature 100 (0.000585)\n",
      "631. feature 531 (0.000584)\n",
      "632. feature 474 (0.000583)\n",
      "633. feature 362 (0.000583)\n",
      "634. feature 442 (0.000583)\n",
      "635. feature 199 (0.000582)\n",
      "636. feature 180 (0.000580)\n",
      "637. feature 671 (0.000577)\n",
      "638. feature 392 (0.000576)\n",
      "639. feature 430 (0.000570)\n",
      "640. feature 605 (0.000570)\n",
      "641. feature 453 (0.000570)\n",
      "642. feature 426 (0.000568)\n",
      "643. feature 278 (0.000567)\n",
      "644. feature 133 (0.000567)\n",
      "645. feature 54 (0.000567)\n",
      "646. feature 279 (0.000567)\n",
      "647. feature 334 (0.000560)\n",
      "648. feature 261 (0.000559)\n",
      "649. feature 23 (0.000556)\n",
      "650. feature 659 (0.000555)\n",
      "651. feature 272 (0.000555)\n",
      "652. feature 530 (0.000552)\n",
      "653. feature 494 (0.000550)\n",
      "654. feature 446 (0.000550)\n",
      "655. feature 352 (0.000548)\n",
      "656. feature 391 (0.000548)\n",
      "657. feature 341 (0.000548)\n",
      "658. feature 496 (0.000544)\n",
      "659. feature 652 (0.000543)\n",
      "660. feature 506 (0.000543)\n",
      "661. feature 198 (0.000543)\n",
      "662. feature 193 (0.000541)\n",
      "663. feature 423 (0.000541)\n",
      "664. feature 260 (0.000540)\n",
      "665. feature 675 (0.000534)\n",
      "666. feature 463 (0.000534)\n",
      "667. feature 144 (0.000533)\n",
      "668. feature 489 (0.000533)\n",
      "669. feature 262 (0.000531)\n",
      "670. feature 564 (0.000530)\n",
      "671. feature 349 (0.000527)\n",
      "672. feature 546 (0.000526)\n",
      "673. feature 683 (0.000525)\n",
      "674. feature 664 (0.000523)\n",
      "675. feature 89 (0.000522)\n",
      "676. feature 97 (0.000522)\n",
      "677. feature 31 (0.000520)\n",
      "678. feature 479 (0.000519)\n",
      "679. feature 346 (0.000517)\n",
      "680. feature 390 (0.000515)\n",
      "681. feature 326 (0.000515)\n",
      "682. feature 250 (0.000513)\n",
      "683. feature 109 (0.000513)\n",
      "684. feature 236 (0.000513)\n",
      "685. feature 206 (0.000512)\n",
      "686. feature 498 (0.000509)\n",
      "687. feature 574 (0.000509)\n",
      "688. feature 668 (0.000506)\n",
      "689. feature 358 (0.000504)\n",
      "690. feature 625 (0.000503)\n",
      "691. feature 455 (0.000502)\n",
      "692. feature 672 (0.000500)\n",
      "693. feature 469 (0.000498)\n",
      "694. feature 471 (0.000495)\n",
      "695. feature 429 (0.000495)\n",
      "696. feature 963 (0.000494)\n",
      "697. feature 210 (0.000492)\n",
      "698. feature 204 (0.000490)\n",
      "699. feature 378 (0.000490)\n",
      "700. feature 294 (0.000489)\n",
      "701. feature 508 (0.000487)\n",
      "702. feature 418 (0.000487)\n",
      "703. feature 170 (0.000487)\n",
      "704. feature 173 (0.000486)\n",
      "705. feature 298 (0.000485)\n",
      "706. feature 228 (0.000484)\n",
      "707. feature 649 (0.000483)\n",
      "708. feature 111 (0.000481)\n",
      "709. feature 396 (0.000481)\n",
      "710. feature 416 (0.000479)\n",
      "711. feature 503 (0.000476)\n",
      "712. feature 158 (0.000475)\n",
      "713. feature 667 (0.000475)\n",
      "714. feature 582 (0.000474)\n",
      "715. feature 181 (0.000474)\n",
      "716. feature 88 (0.000473)\n",
      "717. feature 217 (0.000472)\n",
      "718. feature 339 (0.000472)\n",
      "719. feature 598 (0.000471)\n",
      "720. feature 404 (0.000471)\n",
      "721. feature 178 (0.000469)\n",
      "722. feature 365 (0.000465)\n",
      "723. feature 572 (0.000463)\n",
      "724. feature 58 (0.000462)\n",
      "725. feature 670 (0.000461)\n",
      "726. feature 225 (0.000461)\n",
      "727. feature 499 (0.000460)\n",
      "728. feature 585 (0.000460)\n",
      "729. feature 509 (0.000459)\n",
      "730. feature 580 (0.000457)\n",
      "731. feature 263 (0.000457)\n",
      "732. feature 325 (0.000455)\n",
      "733. feature 502 (0.000454)\n",
      "734. feature 569 (0.000451)\n",
      "735. feature 472 (0.000450)\n",
      "736. feature 186 (0.000448)\n",
      "737. feature 491 (0.000448)\n",
      "738. feature 292 (0.000447)\n",
      "739. feature 12 (0.000445)\n",
      "740. feature 34 (0.000444)\n",
      "741. feature 277 (0.000439)\n",
      "742. feature 954 (0.000438)\n",
      "743. feature 176 (0.000435)\n",
      "744. feature 459 (0.000435)\n",
      "745. feature 377 (0.000435)\n",
      "746. feature 113 (0.000434)\n",
      "747. feature 457 (0.000433)\n",
      "748. feature 562 (0.000432)\n",
      "749. feature 414 (0.000430)\n",
      "750. feature 118 (0.000428)\n",
      "751. feature 439 (0.000427)\n",
      "752. feature 68 (0.000427)\n",
      "753. feature 497 (0.000426)\n",
      "754. feature 136 (0.000424)\n",
      "755. feature 406 (0.000423)\n",
      "756. feature 333 (0.000421)\n",
      "757. feature 232 (0.000418)\n",
      "758. feature 545 (0.000418)\n",
      "759. feature 475 (0.000417)\n",
      "760. feature 447 (0.000413)\n",
      "761. feature 282 (0.000413)\n",
      "762. feature 634 (0.000412)\n",
      "763. feature 130 (0.000412)\n",
      "764. feature 14 (0.000411)\n",
      "765. feature 534 (0.000409)\n",
      "766. feature 179 (0.000408)\n",
      "767. feature 579 (0.000402)\n",
      "768. feature 464 (0.000399)\n",
      "769. feature 208 (0.000399)\n",
      "770. feature 245 (0.000398)\n",
      "771. feature 76 (0.000398)\n",
      "772. feature 371 (0.000397)\n",
      "773. feature 548 (0.000391)\n",
      "774. feature 255 (0.000390)\n",
      "775. feature 79 (0.000389)\n",
      "776. feature 67 (0.000386)\n",
      "777. feature 332 (0.000386)\n",
      "778. feature 106 (0.000384)\n",
      "779. feature 424 (0.000384)\n",
      "780. feature 563 (0.000383)\n",
      "781. feature 151 (0.000382)\n",
      "782. feature 575 (0.000382)\n",
      "783. feature 425 (0.000382)\n",
      "784. feature 205 (0.000380)\n",
      "785. feature 345 (0.000379)\n",
      "786. feature 143 (0.000374)\n",
      "787. feature 266 (0.000374)\n",
      "788. feature 465 (0.000374)\n",
      "789. feature 486 (0.000372)\n",
      "790. feature 188 (0.000372)\n",
      "791. feature 473 (0.000371)\n",
      "792. feature 258 (0.000369)\n",
      "793. feature 650 (0.000369)\n",
      "794. feature 448 (0.000367)\n",
      "795. feature 663 (0.000367)\n",
      "796. feature 589 (0.000365)\n",
      "797. feature 948 (0.000365)\n",
      "798. feature 119 (0.000365)\n",
      "799. feature 187 (0.000364)\n",
      "800. feature 450 (0.000363)\n",
      "801. feature 45 (0.000361)\n",
      "802. feature 252 (0.000360)\n",
      "803. feature 399 (0.000358)\n",
      "804. feature 444 (0.000358)\n",
      "805. feature 403 (0.000358)\n",
      "806. feature 504 (0.000357)\n",
      "807. feature 124 (0.000355)\n",
      "808. feature 116 (0.000355)\n",
      "809. feature 369 (0.000354)\n",
      "810. feature 959 (0.000353)\n",
      "811. feature 295 (0.000352)\n",
      "812. feature 592 (0.000351)\n",
      "813. feature 312 (0.000351)\n",
      "814. feature 233 (0.000350)\n",
      "815. feature 676 (0.000348)\n",
      "816. feature 962 (0.000346)\n",
      "817. feature 310 (0.000345)\n",
      "818. feature 610 (0.000342)\n",
      "819. feature 177 (0.000341)\n",
      "820. feature 533 (0.000338)\n",
      "821. feature 338 (0.000338)\n",
      "822. feature 304 (0.000338)\n",
      "823. feature 597 (0.000337)\n",
      "824. feature 368 (0.000334)\n",
      "825. feature 189 (0.000332)\n",
      "826. feature 521 (0.000332)\n",
      "827. feature 449 (0.000332)\n",
      "828. feature 384 (0.000327)\n",
      "829. feature 343 (0.000327)\n",
      "830. feature 183 (0.000326)\n",
      "831. feature 240 (0.000322)\n",
      "832. feature 38 (0.000320)\n",
      "833. feature 516 (0.000320)\n",
      "834. feature 677 (0.000318)\n",
      "835. feature 544 (0.000315)\n",
      "836. feature 590 (0.000313)\n",
      "837. feature 686 (0.000309)\n",
      "838. feature 476 (0.000307)\n",
      "839. feature 477 (0.000306)\n",
      "840. feature 515 (0.000304)\n",
      "841. feature 182 (0.000302)\n",
      "842. feature 227 (0.000300)\n",
      "843. feature 335 (0.000299)\n",
      "844. feature 201 (0.000296)\n",
      "845. feature 46 (0.000295)\n",
      "846. feature 510 (0.000293)\n",
      "847. feature 364 (0.000293)\n",
      "848. feature 627 (0.000292)\n",
      "849. feature 80 (0.000291)\n",
      "850. feature 374 (0.000288)\n",
      "851. feature 153 (0.000288)\n",
      "852. feature 127 (0.000287)\n",
      "853. feature 415 (0.000287)\n",
      "854. feature 78 (0.000285)\n",
      "855. feature 363 (0.000282)\n",
      "856. feature 595 (0.000282)\n",
      "857. feature 132 (0.000281)\n",
      "858. feature 350 (0.000279)\n",
      "859. feature 607 (0.000277)\n",
      "860. feature 102 (0.000277)\n",
      "861. feature 175 (0.000275)\n",
      "862. feature 614 (0.000275)\n",
      "863. feature 619 (0.000274)\n",
      "864. feature 505 (0.000273)\n",
      "865. feature 229 (0.000267)\n",
      "866. feature 243 (0.000266)\n",
      "867. feature 44 (0.000265)\n",
      "868. feature 318 (0.000263)\n",
      "869. feature 556 (0.000262)\n",
      "870. feature 26 (0.000262)\n",
      "871. feature 367 (0.000261)\n",
      "872. feature 235 (0.000260)\n",
      "873. feature 253 (0.000256)\n",
      "874. feature 30 (0.000256)\n",
      "875. feature 194 (0.000252)\n",
      "876. feature 522 (0.000251)\n",
      "877. feature 573 (0.000251)\n",
      "878. feature 222 (0.000250)\n",
      "879. feature 621 (0.000250)\n",
      "880. feature 42 (0.000249)\n",
      "881. feature 960 (0.000246)\n",
      "882. feature 398 (0.000245)\n",
      "883. feature 616 (0.000240)\n",
      "884. feature 405 (0.000239)\n",
      "885. feature 507 (0.000239)\n",
      "886. feature 344 (0.000238)\n",
      "887. feature 125 (0.000238)\n",
      "888. feature 578 (0.000236)\n",
      "889. feature 636 (0.000233)\n",
      "890. feature 9 (0.000233)\n",
      "891. feature 171 (0.000232)\n",
      "892. feature 145 (0.000231)\n",
      "893. feature 301 (0.000229)\n",
      "894. feature 519 (0.000227)\n",
      "895. feature 543 (0.000226)\n",
      "896. feature 212 (0.000224)\n",
      "897. feature 443 (0.000224)\n",
      "898. feature 537 (0.000219)\n",
      "899. feature 356 (0.000219)\n",
      "900. feature 202 (0.000216)\n",
      "901. feature 103 (0.000216)\n",
      "902. feature 644 (0.000213)\n",
      "903. feature 536 (0.000212)\n",
      "904. feature 287 (0.000211)\n",
      "905. feature 147 (0.000210)\n",
      "906. feature 51 (0.000206)\n",
      "907. feature 513 (0.000204)\n",
      "908. feature 82 (0.000202)\n",
      "909. feature 373 (0.000201)\n",
      "910. feature 682 (0.000200)\n",
      "911. feature 645 (0.000196)\n",
      "912. feature 120 (0.000195)\n",
      "913. feature 492 (0.000194)\n",
      "914. feature 353 (0.000193)\n",
      "915. feature 52 (0.000193)\n",
      "916. feature 950 (0.000192)\n",
      "917. feature 588 (0.000190)\n",
      "918. feature 33 (0.000190)\n",
      "919. feature 961 (0.000189)\n",
      "920. feature 57 (0.000185)\n",
      "921. feature 28 (0.000183)\n",
      "922. feature 29 (0.000182)\n",
      "923. feature 19 (0.000182)\n",
      "924. feature 547 (0.000181)\n",
      "925. feature 40 (0.000181)\n",
      "926. feature 361 (0.000179)\n",
      "927. feature 47 (0.000172)\n",
      "928. feature 83 (0.000166)\n",
      "929. feature 134 (0.000164)\n",
      "930. feature 87 (0.000161)\n",
      "931. feature 315 (0.000160)\n",
      "932. feature 478 (0.000158)\n",
      "933. feature 21 (0.000156)\n",
      "934. feature 22 (0.000156)\n",
      "935. feature 951 (0.000154)\n",
      "936. feature 86 (0.000154)\n",
      "937. feature 169 (0.000151)\n",
      "938. feature 337 (0.000150)\n",
      "939. feature 541 (0.000150)\n",
      "940. feature 92 (0.000149)\n",
      "941. feature 20 (0.000146)\n",
      "942. feature 135 (0.000145)\n",
      "943. feature 48 (0.000145)\n",
      "944. feature 635 (0.000143)\n",
      "945. feature 656 (0.000137)\n",
      "946. feature 528 (0.000135)\n",
      "947. feature 965 (0.000134)\n",
      "948. feature 27 (0.000130)\n",
      "949. feature 460 (0.000125)\n",
      "950. feature 955 (0.000122)\n",
      "951. feature 382 (0.000122)\n",
      "952. feature 957 (0.000120)\n",
      "953. feature 60 (0.000120)\n",
      "954. feature 59 (0.000114)\n",
      "955. feature 952 (0.000112)\n",
      "956. feature 190 (0.000110)\n",
      "957. feature 36 (0.000109)\n",
      "958. feature 91 (0.000089)\n",
      "959. feature 968 (0.000070)\n",
      "960. feature 139 (0.000069)\n",
      "961. feature 32 (0.000064)\n",
      "962. feature 191 (0.000062)\n",
      "963. feature 137 (0.000036)\n",
      "964. feature 141 (0.000030)\n",
      "965. feature 66 (0.000029)\n",
      "966. feature 65 (0.000027)\n",
      "967. feature 138 (0.000026)\n",
      "968. feature 140 (0.000025)\n",
      "969. feature 41 (0.000017)\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf.fit(X, y)\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "#    min_samples_split=3, random_state=0)\n",
    "#scores = cross_val_score(clf, X, y)\n",
    "#scores.mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.45872569e+09,   6.62069611e+00,   4.09600000e+03, ...,\n",
       "          0.00000000e+00,   6.00000000e+00,   6.00000000e+00],\n",
       "       [  1.24536080e+09,   7.25868019e+00,   4.09600000e+03, ...,\n",
       "          0.00000000e+00,   6.00000000e+00,   4.00000000e+00],\n",
       "       [  2.09920000e+06,   7.95576609e+00,   4.09600000e+03, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  2.09920000e+06,   7.87666690e+00,   4.09600000e+03, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.41183984e+09,   6.41797248e+00,   4.09600000e+03, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  1.06883187e+09,   5.65937725e+00,   4.09600000e+03, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 194)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dragonjohn/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "clf.fit(data, label)\n",
    "clf.predict(tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "y = np.array([1, 1, 2, 2])\n",
    "pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt, savetxt\n",
    "savetxt('dataset/submission20160709_1.csv', clf.predict(tdata), delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAA', 'AAD', 'AAM', 'AAS', 'ADC', 'ADD', 'AND', 'ARPL', 'BOUND', 'BSF', 'BSR', 'BSWAP', 'BT', 'BTC', 'BTR', 'BTS', 'CALL', 'CBW', 'CDQ', 'CLC', 'CLD', 'CLI', 'CLTS', 'CMC', 'CMP', 'CMPS', 'CMPXCHG', 'CWD', 'CWDE', 'DAA', 'DAS', 'DEC', 'DIV', 'ENTER', 'ESC', 'HLT', 'IDIV', 'IMUL', 'IN', 'INC', 'INS', 'INT', 'INTO', 'INVD', 'INVLPG', 'IRET', 'IRETD', 'JA', 'JNBE', 'JAE', 'JNB', 'JB', 'JNAE', 'JBE', 'JNA', 'JC', 'JCXZ', 'JECXZ', 'JE', 'JZ', 'JG', 'JNLE', 'JGE', 'JNL', 'JL', 'JNGE', 'JLE', 'JNG', 'JMP', 'JNC', 'JNE', 'JNZ', 'JNO', 'JNS', 'JNP', 'JPO', 'JO', 'JP', 'JPE', 'JS', 'LAHF', 'LAR', 'LDS', 'LEA', 'LEAVE', 'LES', 'LFS', 'LGDT', 'LIDT', 'LGS', 'LLDT', 'LMSW', 'LOCK', 'LODS', 'LOOP', 'LOOPE', 'LOOPZ', 'LOOPNZ', 'LOOPNE', 'LSL', 'LSS', 'LTR', 'MOV', 'MOVS', 'MOVSX', 'MOVZX', 'MUL', 'NEG', 'NOP', 'NOT', 'OR', 'OUT', 'OUTS', 'POP', 'POPA', 'POPAD', 'POPF', 'POPFD', 'PUSH', 'PUSHA', 'PUSHAD', 'PUSHF', 'PUSHFD', 'RCL', 'RCR', 'REP', 'REPE', 'REPZ', 'REPNE', 'REPNZ', 'RET', 'RETF', 'ROL', 'ROR', 'SAHF', 'SAL', 'SHL', 'SAR', 'SBB', 'SCAS', 'SETAE', 'SETNB', 'SETB', 'SETNAE', 'SETBE', 'SETNA', 'SETE', 'SETZ', 'SETNE', 'SETNZ', 'SETL', 'SETNGE', 'SETGE', 'SETNL', 'SETLE', 'SETNG', 'SETG', 'SETNLE', 'SETS', 'SETNS', 'SETC', 'SETNC', 'SETO', 'SETNO', 'SETP', 'SETPE', 'SETNP', 'SETPO', 'SGDT', 'SIDT', 'SHR', 'SHLD', 'SHRD', 'SLDT', 'SMSW', 'STC', 'STD', 'STI', 'STOS', 'STR', 'SUB', 'TEST', 'VERR', 'VERW', 'WAIT', 'FWAIT', 'WBINVD', 'XCHG', 'XLAT', 'XLATB', 'XOR']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# /Users/dragonjohn/Documents/DevEnv/Python/MLCR2malwareDetect/RyuMalwareDetect/\n",
    "asmopcode = 'asm_opcode.txt'\n",
    "\n",
    "opcode_list = []\n",
    "\n",
    "with open(asmopcode, 'rb') as content:\n",
    "    for line in content.readlines():\n",
    "        opcode = line.split(' - ')\n",
    "        if '/' in opcode[0]:\n",
    "            opcode_list.extend([opcode[0].split('/')[0], opcode[0].split('/')[1]])\n",
    "        else:\n",
    "            opcode_list.append(opcode[0])\n",
    "            \n",
    "print opcode_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t\\taaa', '\\t\\taad', '\\t\\taam', '\\t\\taas', '\\t\\tadc', '\\t\\tadd', '\\t\\tand', '\\t\\tarpl', '\\t\\tbound', '\\t\\tbsf', '\\t\\tbsr', '\\t\\tbswap', '\\t\\tbt', '\\t\\tbtc', '\\t\\tbtr', '\\t\\tbts', '\\t\\tcall', '\\t\\tcbw', '\\t\\tcdq', '\\t\\tclc', '\\t\\tcld', '\\t\\tcli', '\\t\\tclts', '\\t\\tcmc', '\\t\\tcmp', '\\t\\tcmps', '\\t\\tcmpxchg', '\\t\\tcwd', '\\t\\tcwde', '\\t\\tdaa', '\\t\\tdas', '\\t\\tdec', '\\t\\tdiv', '\\t\\tenter', '\\t\\tesc', '\\t\\thlt', '\\t\\tidiv', '\\t\\timul', '\\t\\tin', '\\t\\tinc', '\\t\\tins', '\\t\\tint', '\\t\\tinto', '\\t\\tinvd', '\\t\\tinvlpg', '\\t\\tiret', '\\t\\tiretd', '\\t\\tja', '\\t\\tjnbe', '\\t\\tjae', '\\t\\tjnb', '\\t\\tjb', '\\t\\tjnae', '\\t\\tjbe', '\\t\\tjna', '\\t\\tjc', '\\t\\tjcxz', '\\t\\tjecxz', '\\t\\tje', '\\t\\tjz', '\\t\\tjg', '\\t\\tjnle', '\\t\\tjge', '\\t\\tjnl', '\\t\\tjl', '\\t\\tjnge', '\\t\\tjle', '\\t\\tjng', '\\t\\tjmp', '\\t\\tjnc', '\\t\\tjne', '\\t\\tjnz', '\\t\\tjno', '\\t\\tjns', '\\t\\tjnp', '\\t\\tjpo', '\\t\\tjo', '\\t\\tjp', '\\t\\tjpe', '\\t\\tjs', '\\t\\tlahf', '\\t\\tlar', '\\t\\tlds', '\\t\\tlea', '\\t\\tleave', '\\t\\tles', '\\t\\tlfs', '\\t\\tlgdt', '\\t\\tlidt', '\\t\\tlgs', '\\t\\tlldt', '\\t\\tlmsw', '\\t\\tlock', '\\t\\tlods', '\\t\\tloop', '\\t\\tloope', '\\t\\tloopz', '\\t\\tloopnz', '\\t\\tloopne', '\\t\\tlsl', '\\t\\tlss', '\\t\\tltr', '\\t\\tmov', '\\t\\tmovs', '\\t\\tmovsx', '\\t\\tmovzx', '\\t\\tmul', '\\t\\tneg', '\\t\\tnop', '\\t\\tnot', '\\t\\tor', '\\t\\tout', '\\t\\touts', '\\t\\tpop', '\\t\\tpopa', '\\t\\tpopad', '\\t\\tpopf', '\\t\\tpopfd', '\\t\\tpush', '\\t\\tpusha', '\\t\\tpushad', '\\t\\tpushf', '\\t\\tpushfd', '\\t\\trcl', '\\t\\trcr', '\\t\\trep', '\\t\\trepe', '\\t\\trepz', '\\t\\trepne', '\\t\\trepnz', '\\t\\tret', '\\t\\tretf', '\\t\\trol', '\\t\\tror', '\\t\\tsahf', '\\t\\tsal', '\\t\\tshl', '\\t\\tsar', '\\t\\tsbb', '\\t\\tscas', '\\t\\tsetae', '\\t\\tsetnb', '\\t\\tsetb', '\\t\\tsetnae', '\\t\\tsetbe', '\\t\\tsetna', '\\t\\tsete', '\\t\\tsetz', '\\t\\tsetne', '\\t\\tsetnz', '\\t\\tsetl', '\\t\\tsetnge', '\\t\\tsetge', '\\t\\tsetnl', '\\t\\tsetle', '\\t\\tsetng', '\\t\\tsetg', '\\t\\tsetnle', '\\t\\tsets', '\\t\\tsetns', '\\t\\tsetc', '\\t\\tsetnc', '\\t\\tseto', '\\t\\tsetno', '\\t\\tsetp', '\\t\\tsetpe', '\\t\\tsetnp', '\\t\\tsetpo', '\\t\\tsgdt', '\\t\\tsidt', '\\t\\tshr', '\\t\\tshld', '\\t\\tshrd', '\\t\\tsldt', '\\t\\tsmsw', '\\t\\tstc', '\\t\\tstd', '\\t\\tsti', '\\t\\tstos', '\\t\\tstr', '\\t\\tsub', '\\t\\ttest', '\\t\\tverr', '\\t\\tverw', '\\t\\twait', '\\t\\tfwait', '\\t\\twbinvd', '\\t\\txchg', '\\t\\txlat', '\\t\\txlatb', '\\t\\txor']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "asmfilepath = '../dataset-asm-reaserch/train/'\n",
    "feature_list = []\n",
    "feature_list = [[\"md5\"] + opcode_list]\n",
    "\n",
    "opcode_list = ['\\t\\t' + op.lower() for op in opcode_list]\n",
    "\n",
    "print opcode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['md5', 'AAA', 'AAD', 'AAM', 'AAS', 'ADC', 'ADD', 'AND', 'ARPL', 'BOUND', 'BSF', 'BSR', 'BSWAP', 'BT', 'BTC', 'BTR', 'BTS', 'CALL', 'CBW', 'CDQ', 'CLC', 'CLD', 'CLI', 'CLTS', 'CMC', 'CMP', 'CMPS', 'CMPXCHG', 'CWD', 'CWDE', 'DAA', 'DAS', 'DEC', 'DIV', 'ENTER', 'ESC', 'HLT', 'IDIV', 'IMUL', 'IN', 'INC', 'INS', 'INT', 'INTO', 'INVD', 'INVLPG', 'IRET', 'IRETD', 'JA', 'JNBE', 'JAE', 'JNB', 'JB', 'JNAE', 'JBE', 'JNA', 'JC', 'JCXZ', 'JECXZ', 'JE', 'JZ', 'JG', 'JNLE', 'JGE', 'JNL', 'JL', 'JNGE', 'JLE', 'JNG', 'JMP', 'JNC', 'JNE', 'JNZ', 'JNO', 'JNS', 'JNP', 'JPO', 'JO', 'JP', 'JPE', 'JS', 'LAHF', 'LAR', 'LDS', 'LEA', 'LEAVE', 'LES', 'LFS', 'LGDT', 'LIDT', 'LGS', 'LLDT', 'LMSW', 'LOCK', 'LODS', 'LOOP', 'LOOPE', 'LOOPZ', 'LOOPNZ', 'LOOPNE', 'LSL', 'LSS', 'LTR', 'MOV', 'MOVS', 'MOVSX', 'MOVZX', 'MUL', 'NEG', 'NOP', 'NOT', 'OR', 'OUT', 'OUTS', 'POP', 'POPA', 'POPAD', 'POPF', 'POPFD', 'PUSH', 'PUSHA', 'PUSHAD', 'PUSHF', 'PUSHFD', 'RCL', 'RCR', 'REP', 'REPE', 'REPZ', 'REPNE', 'REPNZ', 'RET', 'RETF', 'ROL', 'ROR', 'SAHF', 'SAL', 'SHL', 'SAR', 'SBB', 'SCAS', 'SETAE', 'SETNB', 'SETB', 'SETNAE', 'SETBE', 'SETNA', 'SETE', 'SETZ', 'SETNE', 'SETNZ', 'SETL', 'SETNGE', 'SETGE', 'SETNL', 'SETLE', 'SETNG', 'SETG', 'SETNLE', 'SETS', 'SETNS', 'SETC', 'SETNC', 'SETO', 'SETNO', 'SETP', 'SETPE', 'SETNP', 'SETPO', 'SGDT', 'SIDT', 'SHR', 'SHLD', 'SHRD', 'SLDT', 'SMSW', 'STC', 'STD', 'STI', 'STOS', 'STR', 'SUB', 'TEST', 'VERR', 'VERW', 'WAIT', 'FWAIT', 'WBINVD', 'XCHG', 'XLAT', 'XLATB', 'XOR', 'CreateFile', 'CopyFile', 'DeleteFile', 'MoveFile', 'SetFilePointer', 'ReadFile', 'WriteFile', 'CloseHandle', 'GetFileAttributes', 'SetFileAttributes', 'CreateDirectory', 'GetWindowsDirectory', 'GetSystemDirectory', 'CreateProcess', 'CreateRemoteThread', 'CreateThread', 'WinExec', 'ExitProcess', 'ExitThread', 'TerminateProcess', 'TerminateThread', 'CreateService', 'DeleteService', 'OpenSCManager', 'OpenService', 'StartService', 'CloseServiceHandle', 'RegisterServiceCtrlHandler', 'StartServiceCtrlDispatcher', 'RegCloseKey', 'RegCreateKeyEx', 'RegDeleteKey', 'RegDeleteValue', 'RegEnumKeyEx', 'RegEnumValue', 'RegGetValue', 'RegNotifyChangeKeyValue', 'RegOpenKeyEx', 'RegSetValueEx']]\n"
     ]
    }
   ],
   "source": [
    "asmopcode = 'asm_opcode3.txt'\n",
    "\n",
    "with open(asmopcode, 'rb') as content:\n",
    "    for line in content.read().splitlines():\n",
    "        opcode_list.append(line.lower())\n",
    "        feature_list[0]+=[line]\n",
    "            \n",
    "print feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t\\taaa', '\\t\\taad', '\\t\\taam', '\\t\\taas', '\\t\\tadc', '\\t\\tadd', '\\t\\tand', '\\t\\tarpl', '\\t\\tbound', '\\t\\tbsf', '\\t\\tbsr', '\\t\\tbswap', '\\t\\tbt', '\\t\\tbtc', '\\t\\tbtr', '\\t\\tbts', '\\t\\tcall', '\\t\\tcbw', '\\t\\tcdq', '\\t\\tclc', '\\t\\tcld', '\\t\\tcli', '\\t\\tclts', '\\t\\tcmc', '\\t\\tcmp', '\\t\\tcmps', '\\t\\tcmpxchg', '\\t\\tcwd', '\\t\\tcwde', '\\t\\tdaa', '\\t\\tdas', '\\t\\tdec', '\\t\\tdiv', '\\t\\tenter', '\\t\\tesc', '\\t\\thlt', '\\t\\tidiv', '\\t\\timul', '\\t\\tin', '\\t\\tinc', '\\t\\tins', '\\t\\tint', '\\t\\tinto', '\\t\\tinvd', '\\t\\tinvlpg', '\\t\\tiret', '\\t\\tiretd', '\\t\\tja', '\\t\\tjnbe', '\\t\\tjae', '\\t\\tjnb', '\\t\\tjb', '\\t\\tjnae', '\\t\\tjbe', '\\t\\tjna', '\\t\\tjc', '\\t\\tjcxz', '\\t\\tjecxz', '\\t\\tje', '\\t\\tjz', '\\t\\tjg', '\\t\\tjnle', '\\t\\tjge', '\\t\\tjnl', '\\t\\tjl', '\\t\\tjnge', '\\t\\tjle', '\\t\\tjng', '\\t\\tjmp', '\\t\\tjnc', '\\t\\tjne', '\\t\\tjnz', '\\t\\tjno', '\\t\\tjns', '\\t\\tjnp', '\\t\\tjpo', '\\t\\tjo', '\\t\\tjp', '\\t\\tjpe', '\\t\\tjs', '\\t\\tlahf', '\\t\\tlar', '\\t\\tlds', '\\t\\tlea', '\\t\\tleave', '\\t\\tles', '\\t\\tlfs', '\\t\\tlgdt', '\\t\\tlidt', '\\t\\tlgs', '\\t\\tlldt', '\\t\\tlmsw', '\\t\\tlock', '\\t\\tlods', '\\t\\tloop', '\\t\\tloope', '\\t\\tloopz', '\\t\\tloopnz', '\\t\\tloopne', '\\t\\tlsl', '\\t\\tlss', '\\t\\tltr', '\\t\\tmov', '\\t\\tmovs', '\\t\\tmovsx', '\\t\\tmovzx', '\\t\\tmul', '\\t\\tneg', '\\t\\tnop', '\\t\\tnot', '\\t\\tor', '\\t\\tout', '\\t\\touts', '\\t\\tpop', '\\t\\tpopa', '\\t\\tpopad', '\\t\\tpopf', '\\t\\tpopfd', '\\t\\tpush', '\\t\\tpusha', '\\t\\tpushad', '\\t\\tpushf', '\\t\\tpushfd', '\\t\\trcl', '\\t\\trcr', '\\t\\trep', '\\t\\trepe', '\\t\\trepz', '\\t\\trepne', '\\t\\trepnz', '\\t\\tret', '\\t\\tretf', '\\t\\trol', '\\t\\tror', '\\t\\tsahf', '\\t\\tsal', '\\t\\tshl', '\\t\\tsar', '\\t\\tsbb', '\\t\\tscas', '\\t\\tsetae', '\\t\\tsetnb', '\\t\\tsetb', '\\t\\tsetnae', '\\t\\tsetbe', '\\t\\tsetna', '\\t\\tsete', '\\t\\tsetz', '\\t\\tsetne', '\\t\\tsetnz', '\\t\\tsetl', '\\t\\tsetnge', '\\t\\tsetge', '\\t\\tsetnl', '\\t\\tsetle', '\\t\\tsetng', '\\t\\tsetg', '\\t\\tsetnle', '\\t\\tsets', '\\t\\tsetns', '\\t\\tsetc', '\\t\\tsetnc', '\\t\\tseto', '\\t\\tsetno', '\\t\\tsetp', '\\t\\tsetpe', '\\t\\tsetnp', '\\t\\tsetpo', '\\t\\tsgdt', '\\t\\tsidt', '\\t\\tshr', '\\t\\tshld', '\\t\\tshrd', '\\t\\tsldt', '\\t\\tsmsw', '\\t\\tstc', '\\t\\tstd', '\\t\\tsti', '\\t\\tstos', '\\t\\tstr', '\\t\\tsub', '\\t\\ttest', '\\t\\tverr', '\\t\\tverw', '\\t\\twait', '\\t\\tfwait', '\\t\\twbinvd', '\\t\\txchg', '\\t\\txlat', '\\t\\txlatb', '\\t\\txor', 'createfile', 'copyfile', 'deletefile', 'movefile', 'setfilepointer', 'readfile', 'writefile', 'closehandle', 'getfileattributes', 'setfileattributes', 'createdirectory', 'getwindowsdirectory', 'getsystemdirectory', 'createprocess', 'createremotethread', 'createthread', 'winexec', 'exitprocess', 'exitthread', 'terminateprocess', 'terminatethread', 'createservice', 'deleteservice', 'openscmanager', 'openservice', 'startservice', 'closeservicehandle', 'registerservicectrlhandler', 'startservicectrldispatcher', 'regclosekey', 'regcreatekeyex', 'regdeletekey', 'regdeletevalue', 'regenumkeyex', 'regenumvalue', 'reggetvalue', 'regnotifychangekeyvalue', 'regopenkeyex', 'regsetvalueex']\n"
     ]
    }
   ],
   "source": [
    "print opcode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['md5', 'AAA', 'AAD', 'AAM', 'AAS', 'ADC', 'ADD', 'AND', 'ARPL', 'BOUND', 'BSF', 'BSR', 'BSWAP', 'BT', 'BTC', 'BTR', 'BTS', 'CALL', 'CBW', 'CDQ', 'CLC', 'CLD', 'CLI', 'CLTS', 'CMC', 'CMP', 'CMPS', 'CMPXCHG', 'CWD', 'CWDE', 'DAA', 'DAS', 'DEC', 'DIV', 'ENTER', 'ESC', 'HLT', 'IDIV', 'IMUL', 'IN', 'INC', 'INS', 'INT', 'INTO', 'INVD', 'INVLPG', 'IRET', 'IRETD', 'JA', 'JNBE', 'JAE', 'JNB', 'JB', 'JNAE', 'JBE', 'JNA', 'JC', 'JCXZ', 'JECXZ', 'JE', 'JZ', 'JG', 'JNLE', 'JGE', 'JNL', 'JL', 'JNGE', 'JLE', 'JNG', 'JMP', 'JNC', 'JNE', 'JNZ', 'JNO', 'JNS', 'JNP', 'JPO', 'JO', 'JP', 'JPE', 'JS', 'LAHF', 'LAR', 'LDS', 'LEA', 'LEAVE', 'LES', 'LFS', 'LGDT', 'LIDT', 'LGS', 'LLDT', 'LMSW', 'LOCK', 'LODS', 'LOOP', 'LOOPE', 'LOOPZ', 'LOOPNZ', 'LOOPNE', 'LSL', 'LSS', 'LTR', 'MOV', 'MOVS', 'MOVSX', 'MOVZX', 'MUL', 'NEG', 'NOP', 'NOT', 'OR', 'OUT', 'OUTS', 'POP', 'POPA', 'POPAD', 'POPF', 'POPFD', 'PUSH', 'PUSHA', 'PUSHAD', 'PUSHF', 'PUSHFD', 'RCL', 'RCR', 'REP', 'REPE', 'REPZ', 'REPNE', 'REPNZ', 'RET', 'RETF', 'ROL', 'ROR', 'SAHF', 'SAL', 'SHL', 'SAR', 'SBB', 'SCAS', 'SETAE', 'SETNB', 'SETB', 'SETNAE', 'SETBE', 'SETNA', 'SETE', 'SETZ', 'SETNE', 'SETNZ', 'SETL', 'SETNGE', 'SETGE', 'SETNL', 'SETLE', 'SETNG', 'SETG', 'SETNLE', 'SETS', 'SETNS', 'SETC', 'SETNC', 'SETO', 'SETNO', 'SETP', 'SETPE', 'SETNP', 'SETPO', 'SGDT', 'SIDT', 'SHR', 'SHLD', 'SHRD', 'SLDT', 'SMSW', 'STC', 'STD', 'STI', 'STOS', 'STR', 'SUB', 'TEST', 'VERR', 'VERW', 'WAIT', 'FWAIT', 'WBINVD', 'XCHG', 'XLAT', 'XLATB', 'XOR', 'CreateFile', 'CopyFile', 'DeleteFile', 'MoveFile', 'SetFilePointer', 'ReadFile', 'WriteFile', 'CloseHandle', 'GetFileAttributes', 'SetFileAttributes', 'CreateDirectory', 'GetWindowsDirectory', 'GetSystemDirectory', 'CreateProcess', 'CreateRemoteThread', 'CreateThread', 'WinExec', 'ExitProcess', 'ExitThread', 'TerminateProcess', 'TerminateThread', 'CreateService', 'DeleteService', 'OpenSCManager', 'OpenService', 'StartService', 'CloseServiceHandle', 'RegisterServiceCtrlHandler', 'StartServiceCtrlDispatcher', 'RegCloseKey', 'RegCreateKeyEx', 'RegDeleteKey', 'RegDeleteValue', 'RegEnumKeyEx', 'RegEnumValue', 'RegGetValue', 'RegNotifyChangeKeyValue', 'RegOpenKeyEx', 'RegSetValueEx'], ['00a1cdc35071e794913b4c656c821cb0', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ['02764580578594614650587e07003d6d', 0, 0, 0, 0, 0, 586, 230, 0, 0, 0, 0, 0, 0, 0, 0, 0, 202, 0, 17, 0, 0, 0, 0, 0, 173, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 1, 9, 51, 51, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 8, 11, 0, 0, 0, 0, 0, 0, 0, 74, 56, 0, 42, 0, 42, 0, 13, 0, 148, 0, 0, 43, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 234, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3704, 13, 1, 726, 0, 2, 0, 13, 184, 0, 0, 135, 0, 0, 0, 0, 424, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 141, 0, 0, 0, 0, 0, 45, 16, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 18, 0, 760, 51, 0, 0, 1, 0, 0, 2, 0, 0, 180, 8, 0, 8, 0, 3, 7, 3, 3, 8, 0, 4, 0, 0, 0, 0, 0, 0, 11, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ['035827862965323762607c20d154f4c7', 0, 0, 0, 0, 123, 4656, 1169, 0, 0, 4, 7, 0, 0, 0, 0, 0, 9032, 0, 17, 0, 0, 0, 0, 0, 7347, 0, 0, 6, 6, 0, 0, 390, 113, 0, 0, 0, 11, 197, 1459, 1459, 0, 0, 0, 0, 0, 0, 0, 623, 0, 0, 356, 1006, 0, 732, 0, 0, 0, 0, 0, 9678, 277, 0, 90, 0, 382, 0, 308, 0, 7116, 0, 0, 4722, 0, 59, 1, 0, 0, 3, 0, 145, 0, 0, 0, 6214, 2524, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 76254, 198, 190, 1259, 18, 94, 268, 377, 777, 0, 0, 4592, 0, 0, 2, 0, 4186, 0, 0, 3, 0, 0, 0, 846, 266, 0, 295, 0, 2369, 0, 0, 0, 19, 0, 698, 100, 106, 0, 0, 80, 75, 0, 10, 0, 0, 144, 0, 123, 4, 0, 0, 6, 3, 0, 0, 5, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 333, 33, 12, 0, 0, 0, 0, 0, 0, 0, 2428, 9304, 0, 0, 0, 0, 0, 262, 0, 0, 2725, 0, 0, 0, 0, 6, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ['0a0a821a3b476522b0af0d7d787fd079', 0, 0, 0, 0, 1, 2978, 310, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6511, 0, 49, 0, 0, 0, 0, 0, 2894, 0, 0, 0, 0, 0, 0, 38, 17, 0, 0, 0, 18, 108, 56, 56, 0, 0, 0, 0, 0, 0, 0, 177, 0, 0, 310, 942, 0, 261, 0, 0, 0, 0, 0, 1384, 101, 0, 53, 0, 107, 0, 54, 0, 2102, 0, 0, 1093, 0, 25, 0, 0, 0, 3, 0, 1, 0, 0, 0, 5570, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21069, 30, 18, 245, 9, 53, 17, 17, 178, 0, 0, 2836, 0, 0, 0, 0, 11093, 0, 0, 0, 0, 0, 4, 19, 0, 0, 0, 0, 1441, 0, 0, 0, 0, 0, 73, 265, 49, 0, 0, 0, 1, 0, 1, 0, 0, 40, 0, 22, 12, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 124, 0, 0, 0, 0, 0, 0, 0, 18, 0, 1136, 1128, 0, 0, 0, 0, 0, 1, 0, 0, 1482, 9, 0, 5, 0, 3, 4, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0], ['0a0e8d12d7bdd017aa0820850c45dc21', 0, 0, 1, 0, 1, 121, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 179, 0, 0, 0, 0, 0, 0, 0, 69, 0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 0, 0, 4, 5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 1, 0, 0, 0, 0, 0, 26, 3, 0, 2, 0, 3, 0, 2, 0, 52, 0, 0, 27, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1140, 3, 3, 22, 0, 0, 0, 0, 4, 2, 1, 51, 0, 0, 0, 0, 57, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 88, 6, 0, 0, 1, 0, 0, 0, 0, 0, 9, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ['0a0e9a172d7434bfede995eb6155379d', 0, 0, 0, 0, 1, 87, 28, 0, 0, 0, 1, 0, 0, 0, 0, 0, 122, 0, 1, 0, 0, 0, 0, 0, 38, 0, 0, 1, 0, 0, 0, 72, 0, 0, 0, 0, 0, 0, 73, 73, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 0, 0, 0, 0, 1, 0, 1, 0, 7, 0, 0, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 70, 10, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 385, 0, 0, 5, 0, 0, 16, 0, 20, 1, 0, 28, 0, 0, 0, 0, 298, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 3, 5, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 64, 16, 0, 0, 0, 0, 0, 9, 1, 0, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 3, 0], ['0a0f8385b560c8d77006ae3cd89226c4', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ['0a1d30a3054f63d288fa60ad29635dff', 0, 0, 0, 0, 4, 6836, 756, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11191, 0, 82, 0, 0, 0, 0, 0, 6308, 0, 0, 0, 0, 0, 0, 90, 10, 0, 0, 0, 5, 121, 78, 78, 0, 0, 0, 0, 0, 0, 0, 218, 0, 0, 662, 1223, 0, 298, 0, 0, 0, 0, 0, 4070, 381, 0, 231, 0, 901, 0, 411, 0, 4140, 0, 0, 2616, 0, 64, 4, 0, 0, 4, 0, 2, 0, 0, 0, 6891, 22, 0, 0, 0, 0, 0, 0, 0, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 41158, 68, 27, 300, 38, 58, 40, 69, 560, 0, 0, 6703, 0, 0, 0, 0, 21105, 0, 0, 0, 0, 0, 0, 20, 0, 0, 0, 0, 3243, 0, 44, 20, 0, 0, 135, 652, 69, 0, 0, 2, 0, 0, 0, 0, 0, 22, 0, 71, 11, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 24, 0, 0, 0, 0, 0, 0, 0, 426, 6, 3, 0, 0, 0, 0, 0, 19, 0, 2009, 3530, 0, 0, 0, 0, 0, 0, 0, 0, 3347, 9, 0, 0, 0, 3, 3, 4, 10, 3, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 3, 0, 0, 0, 0, 0, 9, 3], ['0a1f1c039567062c119cd7c188173d6a', 0, 0, 0, 0, 0, 27, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 162, 0, 0, 0, 0, 0, 0, 0, 41, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 6, 0, 1, 0, 0, 0, 0, 0, 91, 4, 0, 0, 0, 9, 0, 9, 0, 18, 0, 0, 44, 0, 2, 0, 0, 0, 0, 0, 25, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 453, 0, 0, 18, 1, 1, 2, 1, 14, 0, 0, 123, 0, 0, 0, 0, 356, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 45, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 38, 128, 0, 0, 0, 0, 0, 0, 0, 0, 69, 3, 0, 4, 0, 0, 0, 3, 6, 0, 3, 3, 0, 4, 3, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 4, 0, 3, 0, 0, 0, 0, 4, 4], ['9717166892536401691f52abb57d5cf8', 2, 0, 2, 0, 814, 18933, 18607, 0, 0, 0, 0, 26, 2, 0, 0, 2, 95258, 1, 208, 0, 6, 13, 0, 5, 40585, 2, 0, 2, 2, 3, 3, 7848, 1037, 0, 0, 0, 80, 3481, 11773, 10597, 2, 1166, 0, 0, 0, 0, 0, 2001, 0, 0, 2019, 8469, 0, 3254, 0, 0, 0, 0, 0, 46519, 734, 0, 201, 0, 1543, 0, 855, 0, 28284, 0, 0, 22388, 0, 596, 21, 0, 2, 46, 0, 306, 2, 0, 9, 50820, 5855, 4, 0, 0, 1, 0, 0, 0, 68, 7, 0, 0, 0, 0, 0, 0, 0, 0, 327166, 1586, 149, 6290, 123, 1223, 44, 520, 11209, 9, 2, 61546, 20, 0, 10, 0, 227698, 50, 0, 10, 0, 4, 1, 1222, 21, 0, 0, 0, 25156, 61, 525, 360, 14, 5, 4943, 391, 1395, 7, 0, 42, 25, 0, 0, 0, 0, 842, 0, 1001, 7, 0, 0, 160, 3, 0, 0, 158, 4, 10, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 4078, 116, 281, 0, 0, 2, 1, 6, 4849, 0, 9351, 37316, 0, 0, 11, 0, 0, 52, 4, 0, 31269, 6, 0, 0, 0, 0, 4, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "for asmfile in os.listdir(asmfilepath):\n",
    "    # print asmfile\n",
    "    # The following table provides a list of x86-Assembler mnemonics, that is not complete. \n",
    "    # Most of them can be found, for others see at www.intel.com\n",
    "    # http://www.mathemainzel.info/files/x86asmref.html\n",
    "    # count add, sub, mov, xor, push, pop, cmp, jz, jnz, je, jne, ja, \n",
    "    with open(asmfilepath+asmfile) as filecontent:\n",
    "        content_feature = [0] * len(opcode_list)\n",
    "\n",
    "        for line in filecontent:\n",
    "            for idx, op in enumerate(opcode_list):\n",
    "                if op in line.lower():\n",
    "                    content_feature[idx] +=1\n",
    "        feature_list += ([[asmfile.split('.asm')[0]] + content_feature])\n",
    "    \n",
    "print feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "output_train_asm = 'dataset/train_asm.csv'\n",
    "with open(output_train_asm, 'wb') as output:\n",
    "    writer = csv.writer( output, delimiter=\",\")\n",
    "    for row in feature_list:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
