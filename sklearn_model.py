import matplotlib.pyplot as plt

import numpy as np

from sklearn.datasets import make_blobs
from sklearn.ensemble import RandomForestClassifier
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import log_loss
#X = data
#y = label
X, y = make_blobs(n_samples=10, n_features=2, random_state=42,
                          cluster_std=5.0)
X_train, y_train = X[:600], y[:600]
X_valid, y_valid = X[600:800], y[600:800]
X_train_valid, y_train_valid = X[:800], y[:800]
X_test, y_test = X[800:], y[800:]
# print y
# array([2, 2, 1, 2, 0, 0, 0, 1, 1, 0])

from sklearn.cross_validation import cross_val_score
from sklearn.datasets import make_blobs
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.tree import DecisionTreeClassifier

X, y = make_blobs(n_samples=10000, n_features=10, centers=100,
            random_state=0)

#clf = RandomForestClassifier(n_estimators=10, max_depth=None,
#    min_samples_split=1, random_state=0)
#scores = cross_val_score(clf, X, y)
#scores.mean()


clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,
            min_samples_split=1, random_state=0)
scores = cross_val_score(clf, X, y)
scores.mean() > 0.999

# print y.shape
# (10000,)


# printX.shape
# (10000, 10)

# print X
# array([[  6.46907649,   4.25070317,  -8.63694437, ...,  -0.48172814,

# print y
# array([85, 64, 93, ..., 98, 80, 91])

import numpy as np
from sklearn.cross_validation import cross_val_score
from sklearn.datasets import make_blobs
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.tree import DecisionTreeClassifier

X = data
y = label.transpose()[0]
#y
#X
#X.shape
#y.shape

# format will the same as example
